{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data in csv file\n",
    "review_static = pd.read_csv('Amazon_Unlocked_Mobile.csv')\n",
    "review = review_static.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>1</td>\n",
       "      <td>I already had a phone with problems... I know ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>2</td>\n",
       "      <td>The charging port was loose. I got that solder...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>2</td>\n",
       "      <td>Phone looks good but wouldn't stay charged, ha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I originally was using the Samsung S2 Galaxy f...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>3</td>\n",
       "      <td>It's battery life is great. It's very responsi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "5  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "6  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "7  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "8  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "9  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \n",
       "0       5  I feel so LUCKY to have found this used (phone...           1.0  \n",
       "1       4  nice phone, nice up grade from my pantach revu...           0.0  \n",
       "2       5                                       Very pleased           0.0  \n",
       "3       4  It works good but it goes slow sometimes but i...           0.0  \n",
       "4       4  Great phone to replace my lost phone. The only...           0.0  \n",
       "5       1  I already had a phone with problems... I know ...           1.0  \n",
       "6       2  The charging port was loose. I got that solder...           0.0  \n",
       "7       2  Phone looks good but wouldn't stay charged, ha...           0.0  \n",
       "8       5  I originally was using the Samsung S2 Galaxy f...           0.0  \n",
       "9       3  It's battery life is great. It's very responsi...           0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413830</th>\n",
       "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>79.95</td>\n",
       "      <td>5</td>\n",
       "      <td>LOVE IT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413831</th>\n",
       "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>79.95</td>\n",
       "      <td>1</td>\n",
       "      <td>Item was listed as new, but was not. When we t...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413832</th>\n",
       "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>79.95</td>\n",
       "      <td>4</td>\n",
       "      <td>good rugged phone that has a long-lasting batt...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413833</th>\n",
       "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>79.95</td>\n",
       "      <td>3</td>\n",
       "      <td>The phone is good</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413834</th>\n",
       "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>79.95</td>\n",
       "      <td>1</td>\n",
       "      <td>used hard</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413835</th>\n",
       "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>79.95</td>\n",
       "      <td>5</td>\n",
       "      <td>another great deal great price</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413836</th>\n",
       "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>79.95</td>\n",
       "      <td>3</td>\n",
       "      <td>Ok</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413837</th>\n",
       "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>79.95</td>\n",
       "      <td>5</td>\n",
       "      <td>Passes every drop test onto porcelain tile!</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413838</th>\n",
       "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>79.95</td>\n",
       "      <td>3</td>\n",
       "      <td>I returned it because it did not meet my needs...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413839</th>\n",
       "      <td>Samsung Convoy U640 Phone for Verizon Wireless...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>79.95</td>\n",
       "      <td>4</td>\n",
       "      <td>Only downside is that apparently Verizon no lo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Product Name Brand Name  Price  \\\n",
       "413830  Samsung Convoy U640 Phone for Verizon Wireless...    Samsung  79.95   \n",
       "413831  Samsung Convoy U640 Phone for Verizon Wireless...    Samsung  79.95   \n",
       "413832  Samsung Convoy U640 Phone for Verizon Wireless...    Samsung  79.95   \n",
       "413833  Samsung Convoy U640 Phone for Verizon Wireless...    Samsung  79.95   \n",
       "413834  Samsung Convoy U640 Phone for Verizon Wireless...    Samsung  79.95   \n",
       "413835  Samsung Convoy U640 Phone for Verizon Wireless...    Samsung  79.95   \n",
       "413836  Samsung Convoy U640 Phone for Verizon Wireless...    Samsung  79.95   \n",
       "413837  Samsung Convoy U640 Phone for Verizon Wireless...    Samsung  79.95   \n",
       "413838  Samsung Convoy U640 Phone for Verizon Wireless...    Samsung  79.95   \n",
       "413839  Samsung Convoy U640 Phone for Verizon Wireless...    Samsung  79.95   \n",
       "\n",
       "        Rating                                            Reviews  \\\n",
       "413830       5                                            LOVE IT   \n",
       "413831       1  Item was listed as new, but was not. When we t...   \n",
       "413832       4  good rugged phone that has a long-lasting batt...   \n",
       "413833       3                                  The phone is good   \n",
       "413834       1                                          used hard   \n",
       "413835       5                     another great deal great price   \n",
       "413836       3                                                 Ok   \n",
       "413837       5        Passes every drop test onto porcelain tile!   \n",
       "413838       3  I returned it because it did not meet my needs...   \n",
       "413839       4  Only downside is that apparently Verizon no lo...   \n",
       "\n",
       "        Review Votes  \n",
       "413830           0.0  \n",
       "413831           0.0  \n",
       "413832           0.0  \n",
       "413833           0.0  \n",
       "413834           0.0  \n",
       "413835           0.0  \n",
       "413836           0.0  \n",
       "413837           0.0  \n",
       "413838           0.0  \n",
       "413839           0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413840, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the shape of the data\n",
    "review.shape\n",
    "#400k reviews generated by Amazon users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rustum's code to clean the data begins here. First remove the columns: 'Product Name' and 'Brand Name'. #TODO, dont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Product Name and Brand Name\n",
    "data_dropped = review.drop(['Product Name','Brand Name'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows which have null values in either Rating, Reviews, Review Votes, or Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>199.99</td>\n",
       "      <td>1</td>\n",
       "      <td>I already had a phone with problems... I know ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>199.99</td>\n",
       "      <td>2</td>\n",
       "      <td>The charging port was loose. I got that solder...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>199.99</td>\n",
       "      <td>2</td>\n",
       "      <td>Phone looks good but wouldn't stay charged, ha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I originally was using the Samsung S2 Galaxy f...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>199.99</td>\n",
       "      <td>3</td>\n",
       "      <td>It's battery life is great. It's very responsi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Price  Rating                                            Reviews  \\\n",
       "0  199.99       5  I feel so LUCKY to have found this used (phone...   \n",
       "1  199.99       4  nice phone, nice up grade from my pantach revu...   \n",
       "2  199.99       5                                       Very pleased   \n",
       "3  199.99       4  It works good but it goes slow sometimes but i...   \n",
       "4  199.99       4  Great phone to replace my lost phone. The only...   \n",
       "5  199.99       1  I already had a phone with problems... I know ...   \n",
       "6  199.99       2  The charging port was loose. I got that solder...   \n",
       "7  199.99       2  Phone looks good but wouldn't stay charged, ha...   \n",
       "8  199.99       5  I originally was using the Samsung S2 Galaxy f...   \n",
       "9  199.99       3  It's battery life is great. It's very responsi...   \n",
       "\n",
       "   Review Votes  \n",
       "0           1.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "5           1.0  \n",
       "6           0.0  \n",
       "7           0.0  \n",
       "8           0.0  \n",
       "9           0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all data where either Rating, Reviews, Review Votes, or Price is null\n",
    "cleaned_data = data_dropped.drop(data_dropped[data_dropped['Rating'].isnull() | data_dropped['Reviews'].isnull() | data_dropped['Review Votes'].isnull() | data_dropped['Price'].isnull()].index)\n",
    "cleaned_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I used the .translate function to remove punctuation from the reviews. Since our dataset is so large, str.replace would take too long and could potentially crash kernels. The translate function is a python function based in C and works very fast. I first join all the items with a character sequence that does not exist in the data: '|aa'. I then translate all the punctuations in the punctuations variable and finally split on this sequence with '|aa'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{}~' \n",
    "translations = str.maketrans(dict.fromkeys(punctuations, ''))\n",
    "\n",
    "cleaned_data['Reviews'] = '|aa'.join(cleaned_data['Reviews'].tolist()).translate(translations).split('|aa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used phone ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone nice up grade from my pantach revue...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone The only ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>199.99</td>\n",
       "      <td>1</td>\n",
       "      <td>I already had a phone with problems I know it ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>199.99</td>\n",
       "      <td>2</td>\n",
       "      <td>The charging port was loose I got that soldere...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>199.99</td>\n",
       "      <td>2</td>\n",
       "      <td>Phone looks good but wouldnt stay charged had ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I originally was using the Samsung S2 Galaxy f...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>199.99</td>\n",
       "      <td>3</td>\n",
       "      <td>Its battery life is great Its very responsive ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Price  Rating                                            Reviews  \\\n",
       "0  199.99       5  I feel so LUCKY to have found this used phone ...   \n",
       "1  199.99       4  nice phone nice up grade from my pantach revue...   \n",
       "2  199.99       5                                       Very pleased   \n",
       "3  199.99       4  It works good but it goes slow sometimes but i...   \n",
       "4  199.99       4  Great phone to replace my lost phone The only ...   \n",
       "5  199.99       1  I already had a phone with problems I know it ...   \n",
       "6  199.99       2  The charging port was loose I got that soldere...   \n",
       "7  199.99       2  Phone looks good but wouldnt stay charged had ...   \n",
       "8  199.99       5  I originally was using the Samsung S2 Galaxy f...   \n",
       "9  199.99       3  Its battery life is great Its very responsive ...   \n",
       "\n",
       "   Review Votes  \n",
       "0           1.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "5           1.0  \n",
       "6           0.0  \n",
       "7           0.0  \n",
       "8           0.0  \n",
       "9           0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This concludes Rustum's cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ben's stopword (meaningless words) cleaning begin here\n",
    "#begins by getting all review entries from all rows in the best ratings =5 and worst ratings =1 and putting into array\n",
    "best = cleaned_data.loc[cleaned_data['Rating'] == 5]['Reviews'].str.cat(sep=' ')\n",
    "worst = cleaned_data.loc[cleaned_data['Rating'] == 1]['Reviews'].str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produces the frequencies of each individual word in both best and worst categories\n",
    "bestlist = Counter(best.split()).most_common()\n",
    "worstlist = Counter(worst.split()).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'I',\n",
       " 'and',\n",
       " 'phone',\n",
       " 'a',\n",
       " 'it',\n",
       " 'to',\n",
       " 'is',\n",
       " 'for',\n",
       " 'this',\n",
       " 'with',\n",
       " 'my',\n",
       " 'of',\n",
       " 'in',\n",
       " 'was',\n",
       " 'that',\n",
       " 'on',\n",
       " 'great',\n",
       " 'but',\n",
       " 'you',\n",
       " 'have',\n",
       " 'as',\n",
       " 'good',\n",
       " 'The',\n",
       " 'very',\n",
       " 'not',\n",
       " 'so',\n",
       " 'It',\n",
       " 'like',\n",
       " 'had',\n",
       " 'all',\n",
       " 'one',\n",
       " 'its',\n",
       " 'use',\n",
       " 'from',\n",
       " 'has',\n",
       " 'be',\n",
       " 'an',\n",
       " 'are',\n",
       " 'This',\n",
       " 'just',\n",
       " 'can',\n",
       " 'screen',\n",
       " 'no',\n",
       " 'new',\n",
       " 'me',\n",
       " 'at',\n",
       " 'than',\n",
       " 'or',\n",
       " 'i',\n",
       " 'battery',\n",
       " 'product',\n",
       " 'really',\n",
       " 'get',\n",
       " 'will',\n",
       " 'phones',\n",
       " 'camera',\n",
       " 'about',\n",
       " 'am',\n",
       " 'time',\n",
       " 'if',\n",
       " 'up',\n",
       " 'would',\n",
       " 'more',\n",
       " 'only',\n",
       " 'out',\n",
       " 'Im',\n",
       " 'when',\n",
       " 'what',\n",
       " 'card',\n",
       " 'any',\n",
       " 'which',\n",
       " 'your',\n",
       " 'got',\n",
       " 'bought',\n",
       " 'buy',\n",
       " 'do',\n",
       " 'dont',\n",
       " 'they',\n",
       " 'other',\n",
       " 'because',\n",
       " 'used',\n",
       " 'work',\n",
       " 'came',\n",
       " 'been',\n",
       " 'now',\n",
       " 'some',\n",
       " 'also',\n",
       " 'even',\n",
       " 'Phone',\n",
       " 'does',\n",
       " 'there',\n",
       " 'by',\n",
       " 'Samsung',\n",
       " 'back',\n",
       " '2',\n",
       " 'purchase',\n",
       " 'seller',\n",
       " 'day',\n",
       " 'first',\n",
       " 'did']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this part iterates through the most first i(currently set at hundred) words of both best and worst reviews and selects words that are\n",
    "#present in both. It stops after the most frequent i(100) words that are in both best and worst reviews have been found.\n",
    "#It returns a list of these words which should suffice as a stop list since if the words can exist in both best and\n",
    "#worst and are commonly found. They don't have bearing on the rating. Made into a function if you feel you need more\n",
    "#stop words. \n",
    "def stop_words(i):\n",
    "    common_words = []\n",
    "    while len(common_words) < 100:\n",
    "        common_words = []\n",
    "        b = [x[0] for x in bestlist][:i]\n",
    "        w = [x[0] for x in worstlist][:i]\n",
    "        for x in range(i): \n",
    "            for y in range(i): \n",
    "                if b[x] == w[y]: \n",
    "                    common_words.append(b[x])\n",
    "        i += 1\n",
    "    return common_words\n",
    "common_words = stop_words(100)\n",
    "common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ben: now we have a list of stop words which can be removed before moel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         I feel so LUCKY to have found this used (phone...\n",
       "1         nice phone, nice up grade from my pantach revu...\n",
       "2                                              Very pleased\n",
       "3         It works good but it goes slow sometimes but i...\n",
       "4         Great phone to replace my lost phone. The only...\n",
       "5         I already had a phone with problems... I know ...\n",
       "6         The charging port was loose. I got that solder...\n",
       "7         Phone looks good but wouldn't stay charged, ha...\n",
       "8         I originally was using the Samsung S2 Galaxy f...\n",
       "9         It's battery life is great. It's very responsi...\n",
       "10        My fiance had this phone previously, but cause...\n",
       "11        This is a great product it came after two days...\n",
       "12        These guys are the best! I had a little situat...\n",
       "13        I'm really disappointed about my phone and ser...\n",
       "14        Ordered this phone as a replacement for the sa...\n",
       "15        Had this phone before and loved it but was not...\n",
       "16        I was able to get the phone I previously owned...\n",
       "17        I brought this phone as a replacement for my d...\n",
       "18        I love the phone. It does everything I need an...\n",
       "19        unfortunately Sprint could not activate the ph...\n",
       "20        The battery was old & had been over used becau...\n",
       "21        pros-beautiful screen,capable of running chrom...\n",
       "22        I purchased this phone in December as a christ...\n",
       "23        Phone good just a little slow phone old but it...\n",
       "24        Phone's speaker little low. Overall very happy...\n",
       "25        the phone was great and in good condition. My ...\n",
       "26        the reasons for the 3 star rating was it was i...\n",
       "27                    Phone works great. No problems at all\n",
       "28             was not in good condition but does work good\n",
       "29        Just... not good. The phone has great screen r...\n",
       "                                ...                        \n",
       "413810    I purchased the Samsung Convoy U640 for my eld...\n",
       "413811    My husband wanted rugged pho?ne for work. He i...\n",
       "413812    I never bought from Amazon before , but I real...\n",
       "413813    Iv'e never quite got used to the iphone and dr...\n",
       "413814    This is by far the best flip phone out there. ...\n",
       "413815    This phone is simple, very good , and it works...\n",
       "413816    Good sturdy phone for a pre-teen to have avail...\n",
       "413817    This is the second junk Convoy I have owned. T...\n",
       "413818    This cell phone provides the just the service ...\n",
       "413819    I BOUGHT THIS PHONE FOR MY HUSBAND AND HE LOVE...\n",
       "413820    They said phone was normal wear but it was a l...\n",
       "413821    You could shoot this out of a potato gun, and ...\n",
       "413822    Bought this for my mother and she loves it. Gr...\n",
       "413823    Excellent phone, as advertised. Love the push-...\n",
       "413824    works great and picks up signal in place my ot...\n",
       "413825    Great phone. Large keys, best flip phone I hav...\n",
       "413826    Pros...Works great, very durable, easy to navi...\n",
       "413827              just as described perfect for the price\n",
       "413828                                       Would not work\n",
       "413829     Speaker phone doesn't work, but phone works good\n",
       "413830                                              LOVE IT\n",
       "413831    Item was listed as new, but was not. When we t...\n",
       "413832    good rugged phone that has a long-lasting batt...\n",
       "413833                                    The phone is good\n",
       "413834                                            used hard\n",
       "413835                       another great deal great price\n",
       "413836                                                   Ok\n",
       "413837          Passes every drop test onto porcelain tile!\n",
       "413838    I returned it because it did not meet my needs...\n",
       "413839    Only downside is that apparently Verizon no lo...\n",
       "Name: Reviews, Length: 413840, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the comments from the data\n",
    "comments = review['Reviews']\n",
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the data type of the reviews\n",
    "type(comments[0])\n",
    "#it is a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we create a list containing all the comments\n",
    "comments_num = comments.shape[0]\n",
    "comments_str = []\n",
    "\n",
    "#filter the data so it only includes comments that are strings\n",
    "#and make it into a list\n",
    "for i in range(comments_num):\n",
    "    if type(comments[i]) == str:\n",
    "        comments_str.append(str(comments[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make all comments into one string\n",
    "transformed_comment = \"\"\n",
    "for reviews in comments_str:\n",
    "    transformed_comment += reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89668420"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word count of all comments\n",
    "len(transformed_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean all punctuations and make all words into a list\n",
    "comment_words = re.split(r'\\W+', transformed_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use a function which builds the dataset for us\n",
    "\n",
    "def build_dataset(words, n_words):\n",
    "    \"\"\"Process raw inputs into a dataset.\"\"\"\n",
    "    \n",
    "    #The first step is setting up a “counter” list, \n",
    "    #which will store the number of times a word is \n",
    "    #found within the data-set. \n",
    "    \n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "    \n",
    "    \"\"\"\n",
    "    The next part of this function creates \n",
    "    a dictionary, called dictionary which is \n",
    "    populated by keys corresponding to each unique word. \n",
    "    The value assigned to each unique word key is simply \n",
    "    an increasing integer count of the size of the dictionary.  \n",
    "    So, for instance, the most common word will receive the \n",
    "    value 1, the second most common the value 2, the third \n",
    "    most common word the value 3, and so on (the integer 0 \n",
    "    is assigned to the ‘UNK’ words).   This step creates a \n",
    "    unique integer value for each word within the vocabulary \n",
    "    – accomplishing the second step of the process which was \n",
    "    defined above.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            index = dictionary[word]\n",
    "        else:\n",
    "            index = 0  # dictionary['UNK']\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement a data collection function\n",
    "\n",
    "def collect_data(vocabulary_size=10000):\n",
    "    #we will use our comment_words here as our vocabulary\n",
    "    data, count, dictionary, reverse_dictionary = build_dataset(comment_words,\n",
    "                                                                vocabulary_size)\n",
    "    return data, count, dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = 0\n",
    "# generate batch data\n",
    "def generate_batch(data, batch_size, num_skips, skip_window):\n",
    "    global data_index\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    context = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1  # [ skip_window input_word skip_window ]\n",
    "    buffer = collections.deque(maxlen=span)\n",
    "    for _ in range(span):\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    for i in range(batch_size // num_skips):\n",
    "        target = skip_window  # input word at the center of the buffer\n",
    "        targets_to_avoid = [skip_window]\n",
    "        for j in range(num_skips):\n",
    "            while target in targets_to_avoid:\n",
    "                target = random.randint(0, span - 1)\n",
    "            targets_to_avoid.append(target)\n",
    "            batch[i * num_skips + j] = buffer[skip_window]  # this is the input word\n",
    "            context[i * num_skips + j, 0] = buffer[target]  # these are the context words\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    # Backtrack a little bit to avoid skipping words in the end of a batch\n",
    "    data_index = (data_index + len(data) - span) % len(data)\n",
    "    return batch, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now collect data\n",
    "vocabulary_size = 10000\n",
    "data, count, dictionary, reverse_dictionary = collect_data(vocabulary_size=vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will be using the skip-gram method instead of CBOW\n",
    "batch_size = 128\n",
    "embedding_size = 300  # Dimension of the embedding vector.\n",
    "skip_window = 2       # How many words to consider left and right.\n",
    "num_skips = 2         # How many times to reuse an input to generate a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We pick a random validation set to sample nearest neighbors. Here we limit the\n",
    "# validation samples to the words that have a low numeric ID, which by\n",
    "# construction are also the most frequent.\n",
    "valid_size = 16     # Random set of words to evaluate similarity on.\n",
    "valid_window = 100  # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
    "num_sampled = 64    # Number of negative examples to sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can start creating the TensorFlow Model for the data\n",
    "\n",
    "graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-32-65836fc8abc1>:25: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-32-65836fc8abc1>:31: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "#Creating the TensorFlow graph\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    train_context = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "    \n",
    "    # Look up embeddings for inputs.\n",
    "    embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "    embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "    \n",
    "    # Construct the variables for the softmax\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal([embedding_size, vocabulary_size],\n",
    "                          stddev=1.0 / math.sqrt(embedding_size)))\n",
    "    biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "    hidden_out = tf.transpose(tf.matmul(tf.transpose(weights), tf.transpose(embed))) + biases\n",
    "    \n",
    "    # convert train_context to a one-hot format\n",
    "    train_one_hot = tf.one_hot(train_context, vocabulary_size)\n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hidden_out, labels=train_one_hot))\n",
    "    \n",
    "    # Construct the SGD optimizer using a learning rate of 1.0.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(cross_entropy)\n",
    "\n",
    "    # Compute the cosine similarity between minibatch examples and all embeddings.\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "    normalized_embeddings = embeddings / norm\n",
    "    valid_embeddings = tf.nn.embedding_lookup(\n",
    "        normalized_embeddings, valid_dataset)\n",
    "    similarity = tf.matmul(\n",
    "        valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "\n",
    "    # Add variable initializer.\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(graph, num_steps):\n",
    "    with tf.Session(graph=graph).as_default() as session:\n",
    "      # We must initialize all variables before we use them.\n",
    "        init.run()\n",
    "        print('Initialized')\n",
    "\n",
    "        average_loss = 0\n",
    "        for step in range(num_steps):\n",
    "            batch_inputs, batch_context = generate_batch(data, batch_size, num_skips, skip_window)\n",
    "            feed_dict = {train_inputs: batch_inputs, train_context: batch_context}\n",
    "\n",
    "        # We perform one update step by evaluating the optimizer op (including it\n",
    "        # in the list of returned values for session.run()\n",
    "            _, loss_val = session.run([optimizer, cross_entropy], feed_dict=feed_dict)\n",
    "            average_loss += loss_val\n",
    "\n",
    "            if step % 2000 == 0:\n",
    "                if step > 0:\n",
    "                    average_loss /= 2000\n",
    "                # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "                print('Average loss at step ', step, ': ', average_loss)\n",
    "                average_loss = 0\n",
    "\n",
    "        # Note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "            if step % 10000 == 0:\n",
    "                sim = similarity.eval()\n",
    "                for i in range(valid_size):\n",
    "                    valid_word = reverse_dictionary[valid_examples[i]]\n",
    "                    top_k = 8  # number of nearest neighbors\n",
    "                    nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n",
    "                    log_str = 'Nearest to %s:' % valid_word\n",
    "                    for k in range(top_k):\n",
    "                        close_word = reverse_dictionary[nearest[k]]\n",
    "                        log_str = '%s %s,' % (log_str, close_word)\n",
    "                    print(log_str)\n",
    "    final_embeddings = normalized_embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Average loss at step  0 :  9.41921615600586\n",
      "Nearest to all: banged, Recommended, Whether, defined, Kit, Shop, Third, factura,\n",
      "Nearest to are: cargador, preventing, fit, which, disappears, replies, Marketplace, describing,\n",
      "Nearest to my: gloves, notable, messenger, managed, accessed, unnecessary, where, reporting,\n",
      "Nearest to an: Vodafone, READ, payment, natural, punch, box, teach, delight,\n",
      "Nearest to now: printing, subway, pods, ACTIVATE, normal, swap, versatile, block,\n",
      "Nearest to to: Tempered, Sometimes, gigantic, Ill, hard, sold, doubts, horrible,\n",
      "Nearest to 2: boost, voicemail, COLOR, usually, NEW, BlueTooth, A916, gadgets,\n",
      "Nearest to what: eating, veces, their, kindly, smudge, high, provide, earphone,\n",
      "Nearest to t: desire, Classic, volume, freezed, teach, Transfer, haha, failed,\n",
      "Nearest to product: actively, Typing, OFF, g, valid, hype, OnePlus, ensure,\n",
      "Nearest to because: examine, blend, handset, United, cosmetic, Ace, 9300, twenty,\n",
      "Nearest to phone: elsewhere, can, screenshot, stands, Premium, higher, gear, stepped,\n",
      "Nearest to apps: asap, protector, 29, interface, Todo, HEAR, Performs, scheduled,\n",
      "Nearest to price: deducted, purpose, concrete, snapped, fighting, honesty, porque, Opera,\n",
      "Nearest to can: phone, proper, part, youExcellent, work, arrives, Gigs, someone,\n",
      "Nearest to on: Thankfully, feedback, retail, General, sure, levanta, manageable, missed,\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value Variable\n\t [[Node: Variable/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable)]]\n\nCaused by op 'Variable/read', defined at:\n  File \"/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/anaconda3/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-32-65836fc8abc1>\", line 12, in <module>\n    tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 259, in __init__\n    constraint=constraint)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 422, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 79, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3263, in identity\n    \"Identity\", input=input, name=name)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value Variable\n\t [[Node: Variable/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable\n\t [[Node: Variable/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-0ee3f7bc5535>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msoftmax_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0msoftmax_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Softmax method took {} minutes to run 100 iterations\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax_end_time\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msoftmax_start_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-8f643a0ee10c>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(graph, num_steps)\u001b[0m\n\u001b[1;32m     34\u001b[0m                         \u001b[0mlog_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s %s,'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlog_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mfinal_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalized_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m     \"\"\"\n\u001b[0;32m--> 707\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5211\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5212\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5213\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable\n\t [[Node: Variable/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable)]]\n\nCaused by op 'Variable/read', defined at:\n  File \"/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/anaconda3/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-32-65836fc8abc1>\", line 12, in <module>\n    tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 259, in __init__\n    constraint=constraint)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 422, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 79, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3263, in identity\n    \"Identity\", input=input, name=name)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value Variable\n\t [[Node: Variable/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable)]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph).as_default() as session:\n",
    "    num_steps = 100\n",
    "    softmax_start_time = dt.datetime.now()\n",
    "    run(graph, num_steps=num_steps)\n",
    "    softmax_end_time = dt.datetime.now()\n",
    "    print(\"Softmax method took {} minutes to run 100 iterations\".format((softmax_end_time-softmax_start_time).total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "\n",
    "    # Construct the variables for the NCE loss\n",
    "    nce_weights = tf.Variable(\n",
    "        tf.truncated_normal([vocabulary_size, embedding_size],\n",
    "                            stddev=1.0 / math.sqrt(embedding_size)))\n",
    "    nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "    nce_loss = tf.reduce_mean(\n",
    "        tf.nn.nce_loss(weights=nce_weights,\n",
    "                       biases=nce_biases,\n",
    "                       labels=train_context,\n",
    "                       inputs=embed,\n",
    "                       num_sampled=num_sampled,\n",
    "                       num_classes=vocabulary_size))\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(nce_loss)\n",
    "\n",
    "    # Add variable initializer.\n",
    "    init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 50000\n",
    "nce_start_time = dt.datetime.now()\n",
    "run(graph, num_steps)\n",
    "nce_end_time = dt.datetime.now()\n",
    "print(\"NCE method took {} minutes to run 100 iterations\".format((nce_end_time-nce_start_time).total_seconds()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing words\n",
    "#lematizing, preprocessing text\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
